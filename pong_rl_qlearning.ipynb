{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c553a95-f506-457c-bed8-e4984adc76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "from math import ceil,floor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf1444c-e61f-4fee-884e-ae77a9b428aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PongAgent:\n",
    "    \n",
    "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
    "\n",
    "        # Creamos la tabla de politicas\n",
    "        if policy is not None:\n",
    "            self._q_table = policy\n",
    "        else:\n",
    "            position = list(game.positions_space.shape)\n",
    "            position.append(len(game.action_space))\n",
    "            self._q_table = np.zeros(position)\n",
    "        \n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.ratio_explotacion = ratio_explotacion\n",
    "\n",
    "    def get_next_step(self, state, game):\n",
    "        \n",
    "        # Damos un paso aleatorio...\n",
    "        next_step = np.random.choice(list(game.action_space))\n",
    "        \n",
    "        # o tomaremos el mejor paso...\n",
    "        if np.random.uniform() <= self.ratio_explotacion:\n",
    "            # tomar el maximo\n",
    "            idx_action = np.random.choice(np.flatnonzero(\n",
    "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
    "                ))\n",
    "            next_step = list(game.action_space)[idx_action]\n",
    "\n",
    "        return next_step\n",
    "\n",
    "    # actualizamos las politicas con las recompensas obtenidas\n",
    "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
    "        idx_action_taken =list(game.action_space).index(action_taken)\n",
    "\n",
    "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
    "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
    "\n",
    "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
    "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
    "        if reached_end:\n",
    "            future_max_q_value = reward_action_taken #maximum reward\n",
    "\n",
    "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
    "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
    "    \n",
    "    def print_policy(self):\n",
    "        for row in np.round(self._q_table,1):\n",
    "            for column in row:\n",
    "                print('[', end='')\n",
    "                for value in column:\n",
    "                    print(str(value).zfill(5), end=' ')\n",
    "                print('] ', end='')\n",
    "            print('')\n",
    "            \n",
    "    def get_policy(self):\n",
    "        return self._q_table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d03b977b-5ddc-4d46-9d2a-4e01b0c57435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PongEnvironment:\n",
    "    \n",
    "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
    "        \n",
    "        self.action_space = ['Arriba','Abajo']\n",
    "        \n",
    "        self._step_penalization = 0\n",
    "        \n",
    "        self.state = [0,0,0]\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        \n",
    "        self.dx = movimiento_px\n",
    "        self.dy = movimiento_px\n",
    "        \n",
    "        filas = ceil(height_px/movimiento_px)\n",
    "        columnas = ceil(width_px/movimiento_px)\n",
    "        \n",
    "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
    "                                                  for y in range(filas)] \n",
    "                                                     for x in range(filas)])\n",
    "\n",
    "        self.lives = max_life\n",
    "        self.max_life=max_life\n",
    "        \n",
    "        self.x = randint(int(width_px/2), width_px) \n",
    "        self.y = randint(0, height_px-10)\n",
    "        \n",
    "        self.player_alto = int(height_px/4)\n",
    "\n",
    "        self.player1 = self.player_alto  # posic. inicial del player\n",
    "        \n",
    "        self.score = 0\n",
    "        \n",
    "        self.width_px = width_px\n",
    "        self.height_px = height_px\n",
    "        self.radio = 2.5\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_reward = 0\n",
    "        self.state = [0,0,0]\n",
    "        self.lives = self.max_life\n",
    "        self.score = 0\n",
    "        self.x = randint(int(self.width_px/2), self.width_px) \n",
    "        self.y = randint(0, self.height_px-10)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, animate=False):\n",
    "        self._apply_action(action, animate)\n",
    "        done = self.lives <=0 # final\n",
    "        reward = self.score\n",
    "        reward += self._step_penalization\n",
    "        self.total_reward += reward\n",
    "        return self.state, reward , done\n",
    "\n",
    "    def _apply_action(self, action, animate=False):\n",
    "        \n",
    "        if action == \"Arriba\":\n",
    "            self.player1 += abs(self.dy)\n",
    "        elif action == \"Abajo\":\n",
    "            self.player1 -= abs(self.dy)\n",
    "            \n",
    "        self.avanza_player()\n",
    "\n",
    "        self.avanza_frame()\n",
    "\n",
    "        if animate:\n",
    "            clear_output(wait=True);\n",
    "            fig = self.dibujar_frame()\n",
    "            plt.show()\n",
    "\n",
    "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
    "    \n",
    "    def detectaColision(self, ball_y, player_y):\n",
    "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def avanza_player(self):\n",
    "        if self.player1 + self.player_alto >= self.height_px:\n",
    "            self.player1 = self.height_px - self.player_alto\n",
    "        elif self.player1 <= -abs(self.dy):\n",
    "            self.player1 = -abs(self.dy)\n",
    "\n",
    "    def avanza_frame(self):\n",
    "        self.x += self.dx\n",
    "        self.y += self.dy\n",
    "        if self.x <= 3 or self.x > self.width_px:\n",
    "            self.dx = -self.dx\n",
    "            if self.x <= 3:\n",
    "                ret = self.detectaColision(self.y, self.player1)\n",
    "\n",
    "                if ret:\n",
    "                    self.score = 10\n",
    "                else:\n",
    "                    self.score = -10\n",
    "                    self.lives -= 1\n",
    "                    if self.lives>0:\n",
    "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
    "                        self.y = randint(0, self.height_px-10)\n",
    "                        self.dx = abs(self.dx)\n",
    "                        self.dy = abs(self.dy)\n",
    "        else:\n",
    "            self.score = 0\n",
    "\n",
    "        if self.y < 0 or self.y > self.height_px:\n",
    "            self.dy = -self.dy\n",
    "\n",
    "    def dibujar_frame(self):\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        a1 = plt.gca()\n",
    "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
    "        a1.set_ylim(-5, self.height_px+5)\n",
    "        a1.set_xlim(-5, self.width_px+5)\n",
    "\n",
    "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
    "        a1.add_patch(circle);\n",
    "        a1.add_patch(rectangle)\n",
    "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
    "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
    "        if self.lives <=0:\n",
    "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
    "        elif self.total_reward >= 1000:\n",
    "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9eb9810-e2d6-4852-ac29-08867019a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
    "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
    "\n",
    "    if game is None:\n",
    "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
    "        \n",
    "    if learner is None:\n",
    "        print(\"Begin new Train!\")\n",
    "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
    "\n",
    "    max_points= -9999\n",
    "    first_max_reached = 0\n",
    "    total_rw=0\n",
    "    steps=[]\n",
    "\n",
    "    for played_games in range(0, rounds):\n",
    "        state = game.reset()\n",
    "        reward, done = None, None\n",
    "        \n",
    "        itera=0\n",
    "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
    "            old_state = np.array(state)\n",
    "            next_action = learner.get_next_step(state, game)\n",
    "            state, reward, done = game.step(next_action, animate=animate)\n",
    "            if rounds > 1:\n",
    "                learner.update(game, old_state, next_action, reward, state, done)\n",
    "            itera+=1\n",
    "        \n",
    "        steps.append(itera)\n",
    "        \n",
    "        total_rw+=game.total_reward\n",
    "        if game.total_reward > max_points:\n",
    "            max_points=game.total_reward\n",
    "            first_max_reached = played_games\n",
    "        \n",
    "        if played_games %500==0 and played_games >1 and not animate:\n",
    "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
    "                \n",
    "    if played_games>1:\n",
    "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
    "        \n",
    "    #learner.print_policy()\n",
    "    \n",
    "    return learner, game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7fdf1ae-8bcf-45ce-bd67-3b2292f130ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin new Train!\n",
      "-- Partidas[ 500 ] Avg.Puntos[ 9 ]  AVG Steps[ 203 ] Max Score[ 120 ]\n",
      "-- Partidas[ 1000 ] Avg.Puntos[ 22 ]  AVG Steps[ 245 ] Max Score[ 300 ]\n",
      "-- Partidas[ 1500 ] Avg.Puntos[ 26 ]  AVG Steps[ 259 ] Max Score[ 300 ]\n",
      "-- Partidas[ 2000 ] Avg.Puntos[ 29 ]  AVG Steps[ 268 ] Max Score[ 300 ]\n",
      "-- Partidas[ 2500 ] Avg.Puntos[ 33 ]  AVG Steps[ 282 ] Max Score[ 300 ]\n",
      "-- Partidas[ 3000 ] Avg.Puntos[ 35 ]  AVG Steps[ 290 ] Max Score[ 300 ]\n",
      "-- Partidas[ 3500 ] Avg.Puntos[ 36 ]  AVG Steps[ 295 ] Max Score[ 380 ]\n",
      "-- Partidas[ 4000 ] Avg.Puntos[ 37 ]  AVG Steps[ 296 ] Max Score[ 380 ]\n",
      "-- Partidas[ 4500 ] Avg.Puntos[ 37 ]  AVG Steps[ 298 ] Max Score[ 380 ]\n",
      "-- Partidas[ 5000 ] Avg.Puntos[ 38 ]  AVG Steps[ 300 ] Max Score[ 380 ]\n",
      "-- Partidas[ 5500 ] Avg.Puntos[ 38 ]  AVG Steps[ 301 ] Max Score[ 380 ]\n",
      "Partidas[ 5999 ] Avg.Puntos[ 40 ] Max score[ 380 ] en partida[ 3236 ]\n"
     ]
    }
   ],
   "source": [
    "learner, game = play(rounds=6000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4044f220-efc0-49d8-ac4f-0ae902aeed4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner2 = PongAgent(game, policy=learner.get_policy())\n",
    "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
    "player = play(rounds=1, learner=learner2, game=game, animate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f7815-7f61-43c7-b37b-a211fde28ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
